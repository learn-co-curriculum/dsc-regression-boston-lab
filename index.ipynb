{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Regression Modeling with the Ames Housing Dataset\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll apply the regression analysis and diagnostics techniques covered in this section to the \"Ames Housing\" dataset. You performed a detailed EDA for this dataset earlier on, and hopefully, you more or less recall how this data is structured! In this lab, you'll use some of the features in this dataset to create a linear model to predict the house price!\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "* Perform a linear regression using statsmodels\n",
    "* Determine if a particular set of data exhibits the assumptions of linear regression\n",
    "* Evaluate a linear regression model by using statistical performance metrics pertaining to overall model and specific parameters\n",
    "* Use the coefficient of determination to determine model performance\n",
    "* Interpret the parameters of a simple linear regression model in relation to what they signify for specific data\n",
    "\n",
    "\n",
    "## Let's get started\n",
    "\n",
    "### Import necessary libraries and load 'ames.csv' as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "ames = pd.read_csv('ames.csv')\n",
    "\n",
    "subset = ['YrSold', 'MoSold', 'Fireplaces', 'TotRmsAbvGrd', 'GrLivArea',\n",
    "          'FullBath', 'YearRemodAdd', 'YearBuilt', 'OverallCond', 'OverallQual', 'LotArea', 'SalePrice']\n",
    "\n",
    "data = ames.loc[:, subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "ames = pd.read_csv('ames.csv')\n",
    "\n",
    "subset = ['YrSold', 'MoSold', 'Fireplaces', 'TotRmsAbvGrd', 'GrLivArea',\n",
    "          'FullBath', 'YearRemodAdd', 'YearBuilt', 'OverallCond', 'OverallQual', 'LotArea', 'SalePrice']\n",
    "\n",
    "data = ames.loc[:, subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the Ames housing data represent the dependent and independent variables. We have taken a subset of all columns available to focus on feature interpretation rather than preprocessing steps. The dependent variable here is the sale price of a house `SalePrice`. The description of the other variables is available on [KAGGLE](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). \n",
    "\n",
    "### Inspect the columns of the dataset and comment on type of variables present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Record your observations here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "# Record your observations here \n",
    "#Â The dataset contains a mix of continuous and categorical data\n",
    "# OverallCond and OverallQual look to be ordered categoricals\n",
    "# There are several time based columns in YrSold, MoSold, YearRemodAdd, and YearBuilt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create histograms for all variables in the dataset and comment on their shape (uniform or not?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "data.hist(figsize=(18,15), bins='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You observations here \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "# You observations here \n",
    "\n",
    "# LotArea, SalePrice, GrLivArea are all continuous and appear to be log normally distributed.\n",
    "# Most values are bunched towards the lower end while there are a few very large values\n",
    "# From the TotRmsAbvGrd feature it looks like most houses have around 6 rooms above ground\n",
    "# We can see that there is an increase in the number of houses built as time goes on. Most houses sold were built in the 2000s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the linearity assumption for all chosen features with target variable using scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(16,15), sharey=True)\n",
    "\n",
    "for ax, column in zip(axes.flatten(), data.columns):\n",
    "    ax.scatter(data[column], data['SalePrice'] / 100_000, label=column, alpha=.1)\n",
    "    ax.set_title(f'Sale Price vs {column}')\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel('Sale Price in $100,000')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your observations here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, your data needs a lot of preprocessing to improve the results. This key behind a Kaggle competition is to process the data in such a way that you can identify the relationships and make predictions in the best possible way. For now, we'll use the dataset untouched and just move on with the regression. The assumptions are not _exactly_ all fulfilled, but they still hold to a level that we can move on. \n",
    "\n",
    "### Let's do Regression \n",
    "\n",
    "Now, let's perform a number of simple regression experiments between the chosen independent variables and the dependent variable (price). You'll do this in a loop and in every iteration, you should pick one of the independent variables. Perform the following steps:\n",
    "\n",
    "* Run a simple OLS regression between independent and dependent variables\n",
    "* Plot the residuals using `sm.graphics.plot_regress_exog()`\n",
    "* Plot a Q-Q plot for regression residuals normality test \n",
    "* Store following values in array for each iteration:\n",
    "    * Independent Variable\n",
    "    * r_squared'\n",
    "    * intercept'\n",
    "    * 'slope'\n",
    "    * 'p-value'\n",
    "    * 'normality (JB)' \n",
    "* Comment on each output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "# import libraries\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "\n",
    "results = []\n",
    "for idx, column in enumerate(data.columns):\n",
    "    print (f\"Ames Housing DataSet - Regression Analysis and Diagnostics for SalePrice~{column}\")\n",
    "    print (\"-------------------------------------------------------------------------------------\")\n",
    "\n",
    "    f = f'SalePrice~{column}'\n",
    "    model = smf.ols(formula=f, data=data).fit()\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(15,12))\n",
    "    fig = sm.graphics.plot_regress_exog(model, column, fig=fig)\n",
    "    fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    results.append([column, model.rsquared, model.params[0], model.params[1], model.pvalues[1], sms.jarque_bera(model.resid)[0]])\n",
    "    input(\"Press Enter to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "pd.DataFrame(results, columns=['ind_var', 'r_squared', 'intercept', 'slope', 'p-value', 'normality (JB)' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your observations here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the results are not very reliable. The best R-Squared is witnessed with `OverallQual`, so in this analysis, this is our best predictor. \n",
    "\n",
    "### How can you improve these results?\n",
    "1. Preprocessing \n",
    "\n",
    "This is where the preprocessing of data comes in. Dealing with outliers, normalizing data, scaling values etc. can help regression analysis get more meaningful results from the given data. \n",
    "\n",
    "2. Advanced Analytical Methods\n",
    "\n",
    "Simple regression is a very basic analysis technique and trying to fit a straight line solution to complex analytical questions may prove to be very inefficient. Later on, you'll explore multiple regression where you can use multiple features **at once** to define a relationship with the outcome. You'll also look at some preprocessing and data simplification techniques and revisit the Ames dataset with an improved toolkit. \n",
    "\n",
    "## Level up - Optional \n",
    "\n",
    "Apply some data wrangling skills that you have learned in the previous section to pre-process the set of independent variables we chose above. You can start off with outliers and think of a way to deal with them. See how it affects the goodness of fit. \n",
    "\n",
    "## Summary \n",
    "\n",
    "In this lab, you applied your skills learned so far on a new data set. You looked at the outcome of your analysis and realized that the data might need some preprocessing to see a clear improvement in the results. You'll pick this back up later on, after learning about more preprocessing techniques and advanced modeling techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
